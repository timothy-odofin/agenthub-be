# LLM Configuration
# Provider settings and model configurations for language models

# Default provider settings
default:
  provider: "${DEFAULT_LLM_PROVIDER:openai}"
  model: "${DEFAULT_LLM_MODEL:gpt-5-mini}"
  temperature: 0.1                     # Conservative temperature for consistency
  max_tokens: 4096                     # Default token limit
  timeout: 30                          # Request timeout in seconds
  max_retries: 3                       # Number of retry attempts

# Provider-specific configurations
openai:
  api_key: "${OPENAI_API_KEY}"       # OpenAI API key from environment
  base_url: "${OPENAI_BASE_URL:https://api.openai.com/v1}"
  model: "${OPENAI_DEFAULT_MODEL:gpt-5-mini}"
  temperature: "${OPENAI_TEMPERATURE:0.1}"
  max_tokens: "${OPENAI_MAX_TOKENS:4096}"
  timeout: "${OPENAI_TIMEOUT:60}"
  display_name: "OpenAI"
  model_versions:
    # Frontier / general chat + coding
    - "gpt-5.2"
    - "gpt-5.2-pro"
    - "gpt-5.1"
    - "gpt-5"
    - "gpt-5-mini"
    - "gpt-5-nano"
    # Omni / multimodal general
    - "gpt-4o"
    - "gpt-4o-mini"

anthropic:
  api_key: "${ANTHROPIC_API_KEY}"    # Anthropic API key from environment
  base_url: "${ANTHROPIC_BASE_URL:https://api.anthropic.com}"
  model: "${ANTHROPIC_DEFAULT_MODEL:claude-sonnet-4-5}"
  temperature: "${ANTHROPIC_TEMPERATURE:0.1}"
  max_tokens: "${ANTHROPIC_MAX_TOKENS:4096}"
  timeout: "${ANTHROPIC_TIMEOUT:60}"
  display_name: "Anthropic (Claude)"
  model_versions:
    - "claude-sonnet-4-5"
    - "claude-opus-4-5"
    - "claude-haiku-4-5"

groq:
  api_key: "${GROQ_API_KEY}"         # Groq API key from environment
  base_url: "${GROQ_BASE_URL:https://api.groq.com/openai/v1}"
  model: "${GROQ_DEFAULT_MODEL:llama-3.1-8b-instant}"
  temperature: "${GROQ_TEMPERATURE:0.7}"
  max_tokens: "${GROQ_MAX_TOKENS:4000}"
  timeout: "${GROQ_TIMEOUT:60}"
  display_name: "Groq"
  model_versions:
    # Production models
    - "llama-3.1-8b-instant"
    - "llama-3.3-70b-versatile"
    - "meta-llama/llama-guard-4-12b"
    - "openai/gpt-oss-120b"
    - "openai/gpt-oss-20b"
    - "whisper-large-v3"
    - "whisper-large-v3-turbo"
    - "groq/compound"
    - "groq/compound-mini"

huggingface:
  api_key: "${HUGGINGFACE_API_KEY}"  # HuggingFace API key from environment
  base_url: "${HUGGINGFACE_BASE_URL:https://api-inference.huggingface.co/models}"
  model: "${HUGGINGFACE_DEFAULT_MODEL:meta-llama/Llama-3.1-8B-Instruct}"
  temperature: "${HUGGINGFACE_TEMPERATURE:0.7}"
  max_tokens: "${HUGGINGFACE_MAX_TOKENS:2000}"
  timeout: "${HUGGINGFACE_TIMEOUT:120}"
  display_name: "HuggingFace"
  model_versions:
    # Llama family
    - "meta-llama/Llama-3.1-8B-Instruct"
    - "meta-llama/Llama-3.1-70B-Instruct"
    # Mistral / Mixtral
    - "mistralai/Mistral-7B-Instruct-v0.3"
    - "mistralai/Mixtral-8x7B-Instruct-v0.1"
    # Gemma
    - "google/gemma-2-9b-it"

ollama:
  base_url: "${OLLAMA_BASE_URL:http://localhost:11434}"
  model: "${OLLAMA_DEFAULT_MODEL:llama3.1}"
  temperature: "${OLLAMA_TEMPERATURE:0.7}"
  timeout: "${OLLAMA_TIMEOUT:120}"
  display_name: "Ollama (Local)"
  model_versions:
    # Llama
    - "llama3.1"
    - "llama3"
    - "llama2"
    # Mistral / Mixtral
    - "mistral"
    - "mixtral"
    # Small/efficient
    - "phi3"
    - "gemma2"
    # Popular "reasoning-ish" open models
    - "deepseek-r1"
    - "gpt-oss"
  keep_alive: "${OLLAMA_KEEP_ALIVE:5m}"

google:
  api_key: "${GOOGLE_API_KEY}"       # Google API key from environment
  base_url: "${GOOGLE_BASE_URL:https://generativelanguage.googleapis.com/v1}"
  model: "${GOOGLE_DEFAULT_MODEL:gemini-1.5-pro-latest}"
  temperature: "${GOOGLE_TEMPERATURE:0.7}"
  max_tokens: "${GOOGLE_MAX_TOKENS:4000}"
  timeout: "${GOOGLE_TIMEOUT:60}"
  display_name: "Google Gemini"
  model_versions:
    - "gemini-1.5-pro-latest"         # Latest Gemini 1.5 Pro (2M context)
    - "gemini-1.5-flash-latest"       # Fastest Gemini 1.5
    - "gemini-1.0-pro-latest"         # Older Gemini 1.0 (cheaper)
    - "gemini-pro-vision"             # Vision capabilities

azure:
  api_key: "${AZURE_OPENAI_API_KEY}" # Azure OpenAI API key from environment
  endpoint: "${AZURE_OPENAI_ENDPOINT}" # Azure OpenAI endpoint URL
  model: "${AZURE_OPENAI_DEPLOYMENT:gpt-4o}" # Deployment name in Azure
  api_version: "${AZURE_OPENAI_API_VERSION:2024-02-15-preview}"
  temperature: "${AZURE_OPENAI_TEMPERATURE:0.1}"
  max_tokens: "${AZURE_OPENAI_MAX_TOKENS:4096}"
  timeout: "${AZURE_OPENAI_TIMEOUT:60}"
  display_name: "Azure OpenAI"
  model_versions:
    # Model families users typically deploy under their own deployment names
    - "gpt-4o"
    - "gpt-4o-mini"
    - "gpt-4-turbo"
    - "gpt-4.1"
    - "gpt-4.1-nano"
    - "o3"
    - "o4-mini"
    - "computer-use-preview"

